## Documentation

The Postgres Performance Farm is a system in charge of running benchmarking tests through different Postgres versions. 

Each benchmark aims to run on a newly installed Postgres, without major changes in the default configurations; however, it is possible to change basic parameters. The install does not depend nor interfere with previously existing installations: all directories and sockets are separate by default.

The currently available test is PgBench, also configurable. Furthermore, the script collects basic system information, such as hardware and operating system. There is also execution of collectd, if available.

##### Terminology

The main assumption of the script is that the most relevant results are collecting running tests through different commits within the Postgres repository. Having the same test ran multiple times without any changes in hardware or version does not provide useful information.

Commonly used words are:

* A run is an execution of the script on a single client;
* A benchmark is a single execution of PgBench;
* A given run can have multiple benchmarks done;
* A run should have at least one benchmark.



### Client script

The client script is written in Python3 and takes care of all the client-side part, i. e. downloading and installing Postgres, starting a cluster, executing tests, collecting system information and then shutting down processes and deleting unnecessary folders.

The workflow can be summarized as:

1. Creating (or recreating) all necessary directories;
2. Checking for existing Postgres clones within the Performance Farm folders, and if so, trying to pull for updates;
3. Saving current branch and commit;
4. If there has been an update, or a clone from scratch, Postgres is built using make;
5. A cluster is initialized and started through pg_ctl;
6. System information is collected;
7. PgBench is executed;
8. Cluster is stopped;
9. Data directory is cleaned;
10. Logs are being attached to results and shipped to the server.

##### Files and folders

* perffarm-client.py: takes care of coordinating the setup of benchmarks, and when everything is initialized runs collectors;
* folders.py: global variables related to default folder structure;
* Benchmarks:
  * pgbench.py: takes care of all PgBench related tasks, such as initialization, run of benchmarks and collecting results;
  * runner.py: wrapper calling PgBench functions and saving output in a file
* Collectors:
  * collectd.py: runs collectd to gather system and database statistics;
  * collector.py: combines other collectors and calls them;
  * system.py: contains a collection of Python3 functions from external modules to extract system information such as CPU usage, kernel configuration and memory;
  * postgres.py: mainly a function that connects to Postgres and selects its settings;
* Post example (removed in later versions): 
  * upload.py: takes the output file and sends it to the API;
* Utils: 
  * cluster.py: initalizes, starts and stops a Postgres cluster;
  * build.py: module which takes care of executing a build from source from a git repository;
  * locking.py: ensures locking of files;
  * logging.py: prints nice logging;
  * misc.py: connects to database and returns available RAM.

##### Tuning settings

The Performance Farm comes with some default settings as well as local settings that can be adjusted. Parameters that can be changed are:

* UPDATE, flag to instruct the script to try to pull for new commits at every execution;
* AUTOMATIC_UPLOAD, flag to enable uploading to the server (works only with a valid machine secret);
* GIT_URL, used to specify the repository to pull from;
* BASE_PATH, folder which will be used for Performance Farm files;
* API_URL, current URL of the server (can be changed for local developing);
* MACHINE_SECRET, identifier of the machine on which benchmarks are being run (generated by the server);
* POSTGRES_CONFIG, basic Postgres parameters;
* DATABASE_NAME, database name;
* PGBENCH_CONFIG, parameters to tune PgBench.

##### Folder structure

All folders used within the Performance Farm are children of BASE_PATH, specified in the settings. Specifically, there are:

* BUILD_PATH, containing files generated by configure;
* INSTALL_PATH, installation directory of make;
* BIN_PATH, bin directory of the Postgres installation;
* OUTPUT_PATH, containing all output files generated by PgBench and the script;
* REPOSITORY_PATH, clone of the Postgres remote in which updates are checked;
* DATADIR_PATH, Postgres data directory, getting removed after every execution;
* SOCKET_PATH, folder for sockets to avoid interfering with other Postgres processes;
* LOG_PATH, containing all logs, errors and messages generated by the script.

##### Interpreting results

Output of the script is saved in a JSON format to take advantage of key-value storage, useful for collecting and parsed.

Results are contained in the output folder. There are two main output files: results.json, containing actual results, and results_complete.json, which is the file getting shipped to the server and is equal to the results file plus all the logs attached in sequence. It lacks human readability, therefore the file which should be checked is the first. 

Main fields of the JSON output are:

* pgbench, with a number of nested objects corresponding to the number of runs, each of them with basic information about latency and tps;

* Linux information, divided in:

  * CPU data, along with system times;
  * OS information, its version and architecture;
  * Memory, containing virtual, swap, mounts;
  * Disk usage with I/O;
  * Process information;
  * Compilers (make and gcc);
  * Collectd results;
  * Postgres configuraton;
  * Meta information (date, time, user name).

  

### API

The API is written in Django and Django-REST, using versions compatible with the Postgres website. Its purposes are:

* Defining a database structure for results;
* Receiving, parsing and inserting data;
* Calculating intermediate values;
* Checking for correctness and completeness when database constraints are not sufficient;
* Exposing endpoints to interact with the database.

##### Database structure

The database is being generated by Django and defined through models. Each folder corresponds to a category, and each model file contains several table definitions related to the same object. 

Benchmarks: 

* Benchmark, table containing all existing types of benchmark and their configuration:
  * benchmark_id;
  * benchmark_type, enum with finite types of test (only current one is PgBench);
  * benchmark_config: string containing the coded configuration of the benchmark (number of clients, RAM size etc).
* PgBenchBenchmark, containing configuration for each specific PgBench benchmark:
  * pgbench_benchmark_id;
  * clients, number of clients;
  * warmup, time of warmup;
  * scale, scaling of the database;
  * duration, duration of each single PgBench execution.
* PgBenchRunStatement, containing the statements (parameter -r of PgBench) for each execution:
  * pgbench_run_statement_id;
  * result_id, foreign key from PgBenchResult;
  * line_id, line of the SQL command;
  * latency, latency of the test;
  * result_id, foreign key for PgBenchStatement to access the description of each statement.
* PgBenchStatement, storing the description of each statement:
  * pgbench_statement_id;
  * statement, text description.

Machines: 

* Machine, table storing all information related to single machines:
  * machine_id;
  * add_time, time of the machine being added;
  * alias, unique textual string giving an human readable identifier;
  * machine_secret, unique string used to pair each machine with each run of tests,only known to machine owner;
  * approved, flag identifying whether the machine is coming from a known user, set by admins;
  * owner_id, foreign key from Users.

Postgres:

* PostgresSettingSet, table with hash representation of each set of Postgres configurations (since files are big, it is easy to hash main parameters to check whether the same configuration exists):
  * postgres_settings_set_id;
  * settings_sha256, hash string.
* PostgresSettings, containing all textual information related to Postgres configuration logs corresponding to each hash string (each line represents a single parameter):
  * postgres_settings_id;
  * db_settings_id, foreign key from PostgresSettingsSet;
  * setting_name, name of the parameter;
  * setting_id, id of the parameter;
  * setting_value, actual value of the parameter.

Runs:

* RunInfo, table corresponding to information for each run (each execution of the script):
  * run_id;
  * machine_id, foreign key from Machines;
  * add_time, time when the server received the test result;
  * os_type, enum containing the main operating systems (Windows, Linux etc.);
  * os_name, specific operating system (Ubuntu, Debian etc.);
  * os_version, version of the operating system;
  * os_config_info, foreign key from Systems containing set of specific information related to the operating system;
  * comp_name, compiler (gcc) name;
  * comp_version, compiler version;
  * benchmark_id, information about the benchmark used in the run;
  * run_received_time, time when the client received the command of starting a run;
  * run_start_time, time when the run is actually executed (might be delayed);
  * run_end_time, end time of the run;
  * git_clone_log;
  * git_clone_runtime;
  * configure_log, related to the configure operation while installing Postgres;
  * configure_runtime;
  * build_log, related to make;
  * build_runtime;
  * install_log, related to make install;
  * install_runtime;
  * cleanup_log, time spent removing the data directory folder;
  * cleanup_runtime;
  * postgres_log, log of all Postgres related operations (pg_ctl);
  * postgres_info, output of pg_settings table and foreign key from PostgresSettingsSet.

Systems:

* LinuxInfo, table storing all information related to Linux operating systems, which so far are the only ones intended to support the Performance Farm but plan to be extended in the future:
  * linux_info_id;
  * cpu_brand;
  * hz;
  * cpu_cores;
  * cpu_times, JSON field containing all reports of cpu times;
  * memory, JSON field with all memory information;
  * swap, JSON field with swap data;
  * mounts, JSON field with mounts list;
  * io, JSON information about input/output;
  * sysctl, text output of systemctl information.

Users:

* Users, Django base model with predefined features such as username, password and email.

